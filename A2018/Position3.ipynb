{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dépendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `C:\\Users\\mbela\\.julia\\registries\\General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[2K\u001b[?25h[1mFetching:\u001b[22m\u001b[39m [========================================>]  98.2 %0.0 %3 % [====================>                    ]  49.1 %\u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [============================>            ]  68.4 % [========================================>]  100.0 %\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `C:\\Users\\mbela\\.julia\\environments\\v0.7\\Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `C:\\Users\\mbela\\.julia\\environments\\v0.7\\Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `C:\\Users\\mbela\\.julia\\environments\\v0.7\\Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m `C:\\Users\\mbela\\.julia\\environments\\v0.7\\Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    },
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: Package MLDataUtils not found in current path:\n- Run `Pkg.add(\"MLDataUtils\")` to install the MLDataUtils package.\n",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Package MLDataUtils not found in current path:\n- Run `Pkg.add(\"MLDataUtils\")` to install the MLDataUtils package.\n",
      "",
      "Stacktrace:",
      " [1] require(::Module, ::Symbol) at .\\loading.jl:817",
      " [2] top-level scope at In[1]:5"
     ]
    }
   ],
   "source": [
    "# Julia 0.7\n",
    "using Pkg\n",
    "Pkg.add(\"PyCall\")\n",
    "Pkg.add(\"PyPlot\")\n",
    "using CSV, DataFrames, Distributions, MultivariateStats, LinearAlgebra, Statistics, PyCall, PyPlot, MLDataUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y seaborn` in root environment\n",
      "└ @ Conda C:\\Users\\mbela\\.julia\\packages\\Conda\\uQitS\\src\\Conda.jl:112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Running `conda install -y pandas` in root environment\n",
      "└ @ Conda C:\\Users\\mbela\\.julia\\packages\\Conda\\uQitS\\src\\Conda.jl:112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PyCall.Conda.add(\"seaborn\")\n",
    "PyCall.Conda.add(\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "31e1c7f7d932797d398b097ee5b58a9b7d4becc5",
    "colab_type": "text",
    "id": "lqkGbGlpJm7E"
   },
   "source": [
    "# Importer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "2ae7d9d684ad712c5edababa715c23225f3b1015",
    "colab": {},
    "colab_type": "code",
    "id": "HSjwoVS-Jm7F"
   },
   "outputs": [
    {
     "ename": "PyCall.PyError",
     "evalue": "PyError ($(Expr(:escape, :(ccall(#= C:\\Users\\mbela\\.julia\\packages\\PyCall\\0jMpb\\src\\pyfncall.jl:44 =# @pysym(:PyObject_Call), PyPtr, (PyPtr, PyPtr, PyPtr), o, pyargsptr, kw))))) <class 'FileNotFoundError'>\nFileNotFoundError(\"File b'train3.csv' does not exist\",)\n  File \"C:\\Users\\mbela\\.julia\\conda\\3\\lib\\site-packages\\pandas\\io\\parsers.py\", line 678, in parser_f\n    return _read(filepath_or_buffer, kwds)\n  File \"C:\\Users\\mbela\\.julia\\conda\\3\\lib\\site-packages\\pandas\\io\\parsers.py\", line 440, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"C:\\Users\\mbela\\.julia\\conda\\3\\lib\\site-packages\\pandas\\io\\parsers.py\", line 787, in __init__\n    self._make_engine(self.engine)\n  File \"C:\\Users\\mbela\\.julia\\conda\\3\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1014, in _make_engine\n    self._engine = CParserWrapper(self.f, **self.options)\n  File \"C:\\Users\\mbela\\.julia\\conda\\3\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1708, in __init__\n    self._reader = parsers.TextReader(src, **kwds)\n  File \"pandas\\_libs\\parsers.pyx\", line 384, in pandas._libs.parsers.TextReader.__cinit__\n  File \"pandas\\_libs\\parsers.pyx\", line 695, in pandas._libs.parsers.TextReader._setup_parser_source\n",
     "output_type": "error",
     "traceback": [
      "PyError ($(Expr(:escape, :(ccall(#= C:\\Users\\mbela\\.julia\\packages\\PyCall\\0jMpb\\src\\pyfncall.jl:44 =# @pysym(:PyObject_Call), PyPtr, (PyPtr, PyPtr, PyPtr), o, pyargsptr, kw))))) <class 'FileNotFoundError'>\nFileNotFoundError(\"File b'train3.csv' does not exist\",)\n  File \"C:\\Users\\mbela\\.julia\\conda\\3\\lib\\site-packages\\pandas\\io\\parsers.py\", line 678, in parser_f\n    return _read(filepath_or_buffer, kwds)\n  File \"C:\\Users\\mbela\\.julia\\conda\\3\\lib\\site-packages\\pandas\\io\\parsers.py\", line 440, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"C:\\Users\\mbela\\.julia\\conda\\3\\lib\\site-packages\\pandas\\io\\parsers.py\", line 787, in __init__\n    self._make_engine(self.engine)\n  File \"C:\\Users\\mbela\\.julia\\conda\\3\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1014, in _make_engine\n    self._engine = CParserWrapper(self.f, **self.options)\n  File \"C:\\Users\\mbela\\.julia\\conda\\3\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1708, in __init__\n    self._reader = parsers.TextReader(src, **kwds)\n  File \"pandas\\_libs\\parsers.pyx\", line 384, in pandas._libs.parsers.TextReader.__cinit__\n  File \"pandas\\_libs\\parsers.pyx\", line 695, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "",
      "Stacktrace:",
      " [1] pyerr_check at C:\\Users\\mbela\\.julia\\packages\\PyCall\\0jMpb\\src\\exception.jl:60 [inlined]",
      " [2] pyerr_check at C:\\Users\\mbela\\.julia\\packages\\PyCall\\0jMpb\\src\\exception.jl:64 [inlined]",
      " [3] macro expansion at C:\\Users\\mbela\\.julia\\packages\\PyCall\\0jMpb\\src\\exception.jl:84 [inlined]",
      " [4] __pycall!(::PyObject, ::Ptr{PyCall.PyObject_struct}, ::PyObject, ::Ptr{Nothing}) at C:\\Users\\mbela\\.julia\\packages\\PyCall\\0jMpb\\src\\pyfncall.jl:44",
      " [5] _pycall!(::PyObject, ::PyObject, ::Tuple{String}, ::Int64, ::Ptr{Nothing}) at C:\\Users\\mbela\\.julia\\packages\\PyCall\\0jMpb\\src\\pyfncall.jl:22",
      " [6] #call#89 at C:\\Users\\mbela\\.julia\\packages\\PyCall\\0jMpb\\src\\pyfncall.jl:11 [inlined]",
      " [7] (::PyObject)(::String) at C:\\Users\\mbela\\.julia\\packages\\PyCall\\0jMpb\\src\\pyfncall.jl:89",
      " [8] top-level scope at In[3]:3"
     ]
    }
   ],
   "source": [
    "# importer les données\n",
    "@pyimport pandas as pd\n",
    "\n",
    "#Les noms peuvent etre à changer et assurez-vous d'avoir le fichier dans votre répertoire courant\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorations des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5288,
     "status": "ok",
     "timestamp": 1544637348090,
     "user": {
      "displayName": "Vincent Dandenault",
      "photoUrl": "https://lh5.googleusercontent.com/-KLM2QKOxAq0/AAAAAAAAAAI/AAAAAAAAABM/AJDTSOSEbjI/s64/photo.jpg",
      "userId": "05230056168443841085"
     },
     "user_tz": 300
    },
    "id": "eKYXTelHz-ue",
    "outputId": "f93c9b4f-7971-47a4-d71b-5461a70b3b08"
   },
   "source": [
    "## Corrélations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5407,
     "status": "ok",
     "timestamp": 1544637348229,
     "user": {
      "displayName": "Vincent Dandenault",
      "photoUrl": "https://lh5.googleusercontent.com/-KLM2QKOxAq0/AAAAAAAAAAI/AAAAAAAAABM/AJDTSOSEbjI/s64/photo.jpg",
      "userId": "05230056168443841085"
     },
     "user_tz": 300
    },
    "id": "e_v2K4IKF7Wf",
    "outputId": "86c7fbaf-5117-46d4-9391-96f8f75dfc81"
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: df not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: df not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[4]:3"
     ]
    }
   ],
   "source": [
    "@pyimport seaborn as sns\n",
    "f, ax = subplots(figsize = (15,15))\n",
    "sns.heatmap(df[:corr](), annot= true, linewidths= .5, fmt = \".2f\", ax=ax)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k5iavqMg7OC-"
   },
   "source": [
    "Comme nous pouvons appercevoir, il se trouve une très forte relation entre les ventes globales d'un jeu et ses ventes en Amérique du Nord. Par conséquent, pour l'explorsation de données, nous allons seulement étudier la relation des différentes variables avec la vente globale. Basée sur cette étude, nous allons ensuite choisir nos variables explicatives pour faire notre modèle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PhwxecWwAfhI"
   },
   "source": [
    "## Critic Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6644,
     "status": "ok",
     "timestamp": 1544637349533,
     "user": {
      "displayName": "Vincent Dandenault",
      "photoUrl": "https://lh5.googleusercontent.com/-KLM2QKOxAq0/AAAAAAAAAAI/AAAAAAAAABM/AJDTSOSEbjI/s64/photo.jpg",
      "userId": "05230056168443841085"
     },
     "user_tz": 300
    },
    "id": "Latciq2h_mLC",
    "outputId": "2ec0534f-38d6-4ff4-8142-6068a173e2ed",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: df not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: df not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[5]:2"
     ]
    }
   ],
   "source": [
    "fig, ax = subplots()\n",
    "scatter(x = df[:Critic_Score], y = df[:Global_Sales], s=5)\n",
    "ylabel(\"Global_Sales\", fontsize = 13)\n",
    "xlabel(\"Critic_Score\", fontsize = 13)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "robBmApZA9U9"
   },
   "source": [
    "Il est possible de constater la présence de données abérrantes (quelques points isolés au dessus de ~20M de ventes). Par exemple, le point qui cumule près de l'axe y=80 est le jeu \"Wii Sports\" inclus avec toutes les consoles Wii vendues (la console a en effet cumulé ~80M de ventes). C'est un cas à part (vendu avec une console à fort succès) qui ne partage rien avec les jeux \"normaux\". Cette donnée sera enlevée sur le DataFrame d'entrainement. Il faudra deplus élaguer le jeu de donnée des autres données abbérantes (le critère sera déterminé plus tard)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RZf52OKg8NdP"
   },
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5cPtVwwG72re"
   },
   "source": [
    "Pour Critic Scores, il nous semble se trouver une tendance linéaire. En effet, on appercoit une tendance linéaire croissante dans le graph. Ainsi, nous allons conserver cette variable pour notre modèle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8y6vdbtoB7bO"
   },
   "source": [
    "## Critic Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7122,
     "status": "ok",
     "timestamp": 1544637350048,
     "user": {
      "displayName": "Vincent Dandenault",
      "photoUrl": "https://lh5.googleusercontent.com/-KLM2QKOxAq0/AAAAAAAAAAI/AAAAAAAAABM/AJDTSOSEbjI/s64/photo.jpg",
      "userId": "05230056168443841085"
     },
     "user_tz": 300
    },
    "id": "QTlJyO87B-ZD",
    "outputId": "5d5a8794-83d8-435d-f556-a542d7df666a"
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: df not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: df not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[6]:2"
     ]
    }
   ],
   "source": [
    "fig, ax = subplots()\n",
    "scatter(x = df[:Critic_Count], y = df[:Global_Sales], s=5)\n",
    "ylabel(\"Global_Sales\", fontsize = 13)\n",
    "xlabel(\"Critic_Count\", fontsize = 13)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l5vpXFe18Rl0"
   },
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rjikeaXh8VAS"
   },
   "source": [
    "Pour Critic Count, il nous semble se trouver une tendance linéaire. En effet, on appercoit une tendance linéaire croissante dans le graphique. Ainsi, nous allons conserver cette variable pour notre modèle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wGAnlsRfB0dl"
   },
   "source": [
    "## User Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7386,
     "status": "ok",
     "timestamp": 1544637350326,
     "user": {
      "displayName": "Vincent Dandenault",
      "photoUrl": "https://lh5.googleusercontent.com/-KLM2QKOxAq0/AAAAAAAAAAI/AAAAAAAAABM/AJDTSOSEbjI/s64/photo.jpg",
      "userId": "05230056168443841085"
     },
     "user_tz": 300
    },
    "id": "XHBKKX8uBfmW",
    "outputId": "232cdea3-69b8-4828-9694-9fe58a2a95d7"
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: df not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: df not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[7]:2"
     ]
    }
   ],
   "source": [
    "fig, ax = subplots()\n",
    "scatter(x = df[:User_Score], y = df[:Global_Sales], s=5)\n",
    "ylabel(\"Global_Sales\", fontsize = 13)\n",
    "xlabel(\"User_Score\", fontsize = 13)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ldED1QgA8bIS"
   },
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mJIC5BGt8dUv"
   },
   "source": [
    "Pour User Scores, il nous semble se trouver une tendance linéaire. En effet, on appercoit une tendance linéaire croissante dans le graphique. Ainsi, nous allons conserver cette variable pour notre modèle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y5jzg3hICHFz"
   },
   "source": [
    "## User Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7657,
     "status": "ok",
     "timestamp": 1544637350610,
     "user": {
      "displayName": "Vincent Dandenault",
      "photoUrl": "https://lh5.googleusercontent.com/-KLM2QKOxAq0/AAAAAAAAAAI/AAAAAAAAABM/AJDTSOSEbjI/s64/photo.jpg",
      "userId": "05230056168443841085"
     },
     "user_tz": 300
    },
    "id": "P0Ewt90SBfto",
    "outputId": "076edf0b-6985-4d3e-9d73-82bcba9ec3bc"
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: df not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: df not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[8]:2"
     ]
    }
   ],
   "source": [
    "fig, ax = subplots()\n",
    "scatter(x = df[:User_Count], y = df[:Global_Sales], s=5)\n",
    "ylabel(\"Global_Sales\", fontsize = 13)\n",
    "xlabel(\"User_Count\", fontsize = 13)\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u5EZzlLA8m_u"
   },
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VHpNCyvU8o8G"
   },
   "source": [
    "Pour User Count, à première vue, nous ne savons pas s'il se trouve une régression linéaire. À vrai dire, on appercoit une tendance linéaire croissante dans le graph, mais celle-ci n'est pas prononcée. Ainsi, nous allons conserver cette variable pour notre modèle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-WDWMTwKKub_"
   },
   "source": [
    "## Platfroms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3aiNo5cr86E-"
   },
   "source": [
    "Pour la variable Platform, nous n'avons pas de corrélation connue entre la platform et son nombre de ventes. Nous allons donc calculer cette relation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3mRoFC97hV0K"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "donut_chart (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function donut_chart(column; palette=\"Set2\")\n",
    "    values = column[:value_counts]()[:values]\n",
    "    labels = column[:value_counts]()[:index]\n",
    "    pie(values, colors=sns.color_palette(palette), \n",
    "            labels=labels, autopct=\"%1.1f%%\", \n",
    "            startangle=90, pctdistance=0.85)\n",
    "    #draw circle\n",
    "    centre_circle = plt[:Circle]((0,0), 0.70; fc=\"white\")\n",
    "    fig = plt[:gcf]()\n",
    "    fig[:gca]()[:add_artist](centre_circle)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7640,
     "status": "ok",
     "timestamp": 1544637350613,
     "user": {
      "displayName": "Vincent Dandenault",
      "photoUrl": "https://lh5.googleusercontent.com/-KLM2QKOxAq0/AAAAAAAAAAI/AAAAAAAAABM/AJDTSOSEbjI/s64/photo.jpg",
      "userId": "05230056168443841085"
     },
     "user_tz": 300
    },
    "id": "WbC0hqYuhBi7",
    "outputId": "7edec1b4-1068-4c22-d77d-09804ec0b222"
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: df not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: df not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[10]:1"
     ]
    }
   ],
   "source": [
    "df[:Platform][:unique]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8059,
     "status": "ok",
     "timestamp": 1544637351043,
     "user": {
      "displayName": "Vincent Dandenault",
      "photoUrl": "https://lh5.googleusercontent.com/-KLM2QKOxAq0/AAAAAAAAAAI/AAAAAAAAABM/AJDTSOSEbjI/s64/photo.jpg",
      "userId": "05230056168443841085"
     },
     "user_tz": 300
    },
    "id": "-xTIq-s99T5t",
    "outputId": "a0d2a539-1b01-455a-b3ec-123ba4708caf"
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: df not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: df not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[11]:1"
     ]
    }
   ],
   "source": [
    "donut_chart(df[:Platform])\n",
    "title(\"Groups of platforms\")\n",
    "axis(\"equal\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pybuiltin(\"round\")(5.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8659,
     "status": "ok",
     "timestamp": 1544637351656,
     "user": {
      "displayName": "Vincent Dandenault",
      "photoUrl": "https://lh5.googleusercontent.com/-KLM2QKOxAq0/AAAAAAAAAAI/AAAAAAAAABM/AJDTSOSEbjI/s64/photo.jpg",
      "userId": "05230056168443841085"
     },
     "user_tz": 300
    },
    "id": "gBd_rtEV5RTH",
    "outputId": "3ab13f48-65f3-4de8-c66c-e4cf916f8b57"
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: df not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: df not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[13]:1"
     ]
    }
   ],
   "source": [
    "x = df[:groupby]([:Platform])[:sum]()[:copy]()\n",
    "ax = x[:Global_Sales][:sort_values](ascending=true)[:plot](kind=\"bar\", figsize=(13, 5));\n",
    "\n",
    "for p in ax[:patches]\n",
    "    test = pybuiltin(\"str\")(pybuiltin(\"round\")( p[:get_height]() )) \n",
    "    test1 = pybuiltin(\"str\")(pybuiltin(\"round\")( p[:get_height]() /89.170 ))\n",
    "    test3 = \"$test\\n$test1%\"\n",
    "    annotate(test3, \n",
    "            (p[:get_x]() * 1.007, p[:get_height]() * 0.75),\n",
    "            color=\"black\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6xKwjVKM9Rqp"
   },
   "source": [
    "Comme nous pouvons appercevoir, nous avons beaucoup trop de Platforms qui représentent peu de ventes totales.\n",
    "Nous allons donc faire des groupes. Les groupes sont classés selon ce qui nous semble naturel a priori, c'est-à-dire les types d'utilisateurs  de jeu vidéo que nous connaissons. Une hypothèse raisonnable serait d'affirmer que les tendances des consoles de même \"marques\" sont homogènes. Ainsi les utilisateurs PC par exemple, seront moins portés à expérimenter les jeux de Nintendo.\n",
    "\n",
    "Reste à voir, en analysant les résultats du modèle, si cette intuition est sensée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NM9MQeIihGbw"
   },
   "outputs": [],
   "source": [
    "platforms = py\"{\\\"Playstation\\\" : [\\\"PS\\\", \\\"PS2\\\", \\\"PS3\\\", \\\"PS4\\\"],\n",
    "             \\\"Xbox\\\" : [\\\"XB\\\", \\\"X360\\\", \\\"XOne\\\"], \n",
    "             \\\"PC\\\" : [\\\"PC\\\"],\n",
    "             \\\"Nintendo\\\" : [\\\"Wii\\\", \\\"WiiU\\\"],\n",
    "             \\\"Portable\\\" : [\\\"GB\\\", \\\"GBA\\\", \\\"GC\\\", \\\"DS\\\", \\\"3DS\\\", \\\"PSP\\\", \\\"PSV\\\"]}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le groupage sera effectué sur les données Julia dans les sections de création du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fPpGVeW2-hE-"
   },
   "source": [
    "#### Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B3HXdNWT-jqq"
   },
   "source": [
    "Pour la platform, nous avons une relation claire entre les différents groupes de platforms et le nombre de ventes Globales. Nous allons donc garder cette variable pour notre modèle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "39AEDpdmhmda"
   },
   "source": [
    "## Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9310,
     "status": "ok",
     "timestamp": 1544637352358,
     "user": {
      "displayName": "Vincent Dandenault",
      "photoUrl": "https://lh5.googleusercontent.com/-KLM2QKOxAq0/AAAAAAAAAAI/AAAAAAAAABM/AJDTSOSEbjI/s64/photo.jpg",
      "userId": "05230056168443841085"
     },
     "user_tz": 300
    },
    "id": "YI8pCFb_huGB",
    "outputId": "cd30ba58-8517-41b7-df00-6cc253c2fb8c"
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: df not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: df not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[15]:1"
     ]
    }
   ],
   "source": [
    "df[:Genre][:unique]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9535,
     "status": "ok",
     "timestamp": 1544637352596,
     "user": {
      "displayName": "Vincent Dandenault",
      "photoUrl": "https://lh5.googleusercontent.com/-KLM2QKOxAq0/AAAAAAAAAAI/AAAAAAAAABM/AJDTSOSEbjI/s64/photo.jpg",
      "userId": "05230056168443841085"
     },
     "user_tz": 300
    },
    "id": "SbtVfJRBHEmV",
    "outputId": "7d77e379-815d-49be-de26-a49c169d25e5"
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: df not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: df not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[16]:1"
     ]
    }
   ],
   "source": [
    "donut_chart(df[\"Genre\"], palette=\"muted\")\n",
    "title(\"Genres\")\n",
    "axis(\"equal\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9881,
     "status": "ok",
     "timestamp": 1544637352963,
     "user": {
      "displayName": "Vincent Dandenault",
      "photoUrl": "https://lh5.googleusercontent.com/-KLM2QKOxAq0/AAAAAAAAAAI/AAAAAAAAABM/AJDTSOSEbjI/s64/photo.jpg",
      "userId": "05230056168443841085"
     },
     "user_tz": 300
    },
    "id": "qEU2Hr7khoqB",
    "outputId": "a6c27002-fb64-4111-fb41-e3898c4b8e49"
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: df not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: df not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[17]:1"
     ]
    }
   ],
   "source": [
    "x = df[:groupby]([\"Genre\"])[:sum]()[:copy]()\n",
    "ax = x[:Global_Sales][:sort_values](ascending=true)[:plot](kind=\"bar\", figsize=(13, 5));\n",
    "\n",
    "for p in ax[:patches]\n",
    "    test = pybuiltin(\"str\")(pybuiltin(\"round\")( p[:get_height]() )) \n",
    "    test1 = pybuiltin(\"str\")(pybuiltin(\"round\")( p[:get_height]() /89.170 ))\n",
    "    test3 = \"$test\\n$test1%\"\n",
    "    annotate(test3, \n",
    "            (p[:get_x]() * 1.007, p[:get_height]() * 0.75),\n",
    "            color=\"black\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OMosPEVN_HEV"
   },
   "source": [
    "Comme nous pouvons appercevoir, nous avons quelques genre qui représentent très peu de ventes globales. Ainsi, nous nous allons grouper les genres qui sont moins populaires. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le groupage sera effectué sur les données Julia dans les sections de création du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Ng2klIu_4_E"
   },
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UgCcoUai_he-"
   },
   "source": [
    "Même si nous appercevons une tendance claire, nous n'allons pas choisir cette variable pour notre modèle puisque nous voulons limiter le nombre de variables dans notre permier modèle. De plus, la moitié des genres de semble pas représenter beaucoup de ventes. Donc, nous ne prennons pas cette variable pour notre modèle. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Rm9kGwIlM7z"
   },
   "source": [
    "## Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xTyAoRBolpt0"
   },
   "source": [
    "Graph de pourcentage de ventes par rapport aux rating des jeux selon les années."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10844,
     "status": "ok",
     "timestamp": 1544637353981,
     "user": {
      "displayName": "Vincent Dandenault",
      "photoUrl": "https://lh5.googleusercontent.com/-KLM2QKOxAq0/AAAAAAAAAAI/AAAAAAAAABM/AJDTSOSEbjI/s64/photo.jpg",
      "userId": "05230056168443841085"
     },
     "user_tz": 300
    },
    "id": "o4BwbxYhhowZ",
    "outputId": "ba7952c7-a467-4630-e066-e0d942c5ecda"
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: df not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: df not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[18]:1"
     ]
    }
   ],
   "source": [
    "rating_sales_percentages_by_year = (df[:groupby]([\"Year_of_Release\", \"Rating\"])[:Global_Sales][:sum]())*(100)/df[:groupby]([\"Year_of_Release\"])[:Global_Sales][:sum]()\n",
    "rating_sales_percentages_by_year[:unstack]()[:plot](kind=\"area\",stacked=true, colormap= \"Spectral\", figsize=(13, 4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4zqa1MnhAFek"
   },
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "avIu_cCvAZ5I"
   },
   "source": [
    "Il est a noter que la portion non colorée représente les jeux n'ayant pas été classés. Ainsi, nous observons énormément de valeurs manquantes. De plus, il semble y avoir seulement 4 catégories qui ont une proportion significative des ventes. Par conséquent, nous rejettons cette variable.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-mxIv8VPCWhl"
   },
   "source": [
    "# Choix de variables et traitement de données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10833,
     "status": "ok",
     "timestamp": 1544637353982,
     "user": {
      "displayName": "Vincent Dandenault",
      "photoUrl": "https://lh5.googleusercontent.com/-KLM2QKOxAq0/AAAAAAAAAAI/AAAAAAAAABM/AJDTSOSEbjI/s64/photo.jpg",
      "userId": "05230056168443841085"
     },
     "user_tz": 300
    },
    "id": "o9HReAUQCb4D",
    "outputId": "e12b5b7d-4bff-4d3f-a143-a69c23ccc47d"
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: df not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: df not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[19]:1"
     ]
    }
   ],
   "source": [
    "df[:corr]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5c_wOATzCuxR"
   },
   "source": [
    "Nous allons choisir nos variables explicatives à mettre dans notre modèle dans ce tableau. Les variables retenues pour prédire NA_Sales et Global_Sales sont : JA_Sales, Other_Sales, Critic_Score, Critic_Count, User_Score,  User_Count, Grouped_Platform et Grouped_Rating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g2nGDOToCQAD"
   },
   "source": [
    "# Données manquantes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11703,
     "status": "ok",
     "timestamp": 1544637354877,
     "user": {
      "displayName": "Vincent Dandenault",
      "photoUrl": "https://lh5.googleusercontent.com/-KLM2QKOxAq0/AAAAAAAAAAI/AAAAAAAAABM/AJDTSOSEbjI/s64/photo.jpg",
      "userId": "05230056168443841085"
     },
     "user_tz": 300
    },
    "id": "CqMWd8tdVoru",
    "outputId": "7735ab45-d9be-4176-eeb7-edd9e70485b6"
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: df not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: df not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[20]:1"
     ]
    }
   ],
   "source": [
    "print(\"Taille du jeu de donnée complet : $(df[:shape])\\n\\n\")\n",
    "print(\"Nombre de données manquantes par colonne:\")\n",
    "df[:isnull]()[:sum]()[:sort_values](ascending=false)[:head](20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3EaT9jUtFfm4"
   },
   "source": [
    "Il manque ainsi énormément de données (~50%) pour les colonnes User count, User_Score, Critic_Count, Critic_Score. C'est problémtatique puisque ces variables semblent être corrélés avec les ventes. Cette disparité devra être traitée plus tard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file C:\\Users\\mbela\\.julia\\compiled\\v0.7\\Gadfly\\DvECm.ji for Gadfly [c91e804a-d5a3-530f-b6f0-dfbca275c004]\n",
      "└ @ Base loading.jl:1185\n",
      "┌ Info: Loading DataFrames support into Gadfly.jl\n",
      "└ @ Gadfly C:\\Users\\mbela\\.julia\\packages\\Gadfly\\09PWZ\\src\\mapping.jl:228\n"
     ]
    },
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: Package MLDataUtils not found in current path:\n- Run `Pkg.add(\"MLDataUtils\")` to install the MLDataUtils package.\n",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Package MLDataUtils not found in current path:\n- Run `Pkg.add(\"MLDataUtils\")` to install the MLDataUtils package.\n",
      "",
      "Stacktrace:",
      " [1] require(::Module, ::Symbol) at .\\loading.jl:817",
      " [2] top-level scope at In[21]:1"
     ]
    }
   ],
   "source": [
    "using CSV, DataFrames, Gadfly, Statistics, LinearAlgebra, GLM, Distributions, MLDataUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation de notre meilleur modèle statistique "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement de donné pour les données d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: \"train3.csv\" is not a valid file",
     "output_type": "error",
     "traceback": [
      "ArgumentError: \"train3.csv\" is not a valid file",
      "",
      "Stacktrace:",
      " [1] #File#1(::Int64, ::Bool, ::Int64, ::Nothing, ::Int64, ::Nothing, ::Bool, ::Nothing, ::Bool, ::Array{String,1}, ::String, ::String, ::Bool, ::Char, ::Nothing, ::Nothing, ::Char, ::Nothing, ::Nothing, ::Nothing, ::Nothing, ::Nothing, ::Dict{Type,Type}, ::Symbol, ::Bool, ::Bool, ::Bool, ::Bool, ::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::Type, ::String) at C:\\Users\\mbela\\.julia\\packages\\CSV\\eWuJV\\src\\CSV.jl:135",
      " [2] Type at C:\\Users\\mbela\\.julia\\packages\\CSV\\eWuJV\\src\\CSV.jl:135 [inlined]",
      " [3] #read#105(::Bool, ::Dict{Int64,Function}, ::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::Function, ::String, ::Type) at C:\\Users\\mbela\\.julia\\packages\\CSV\\eWuJV\\src\\CSV.jl:310",
      " [4] read at C:\\Users\\mbela\\.julia\\packages\\CSV\\eWuJV\\src\\CSV.jl:300 [inlined] (repeats 2 times)",
      " [5] top-level scope at In[22]:1"
     ]
    }
   ],
   "source": [
    "train = CSV.read(\"train.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer des variables d'ingénieries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Création d'une nouvelle variable d'ingénierie qui indique si le jeu vidéo a un Critic_Count et un User_Count. Dans des versions précédentes de ce modèle, nous n'avions pas créé cette variable d'ingénierie. Nous avions plutot opter pour l'utilisation de la variable Critic_Count et User_Count comme variable explicative des modèles. Cependant, en traitant les données, nous avons pu remarquer, qu'en moyenne, il manquait environ 54% des valeurs de Critic_Count et User_Count pour chaque plateforme. Alors, lorsque nous traitions le Critic_Count et User_Count dans l'ancien modèle, nous remplissions les données manquantes la moyenne de chacune. Ceci était inéficace, car il manquait trop de donnés alors en mettant la moyenne pour toutes les données manquantes nous introduisions un biais dans notre traitement de donnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: train not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: train not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[23]:1"
     ]
    }
   ],
   "source": [
    "\n",
    "userCount = collect(train[:User_Count])\n",
    "criticCount = collect(train[:Critic_Count])\n",
    "hasCount = userCount\n",
    "\n",
    "for i in eachindex(userCount)\n",
    "    if typeof((userCount[i])) == Missing || typeof((criticCount[i])) == Missing\n",
    "        hasCount[i] = 0\n",
    "        \n",
    "    else\n",
    "        hasCount[i] = 1 \n",
    "        \n",
    "    end\n",
    "end\n",
    "train[:Has_Count] = hasCount\n",
    "first(train,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) \n",
    "Création d'un nouvelle variable d'ingénierie qui indique si le jeu video fait partie de l'une des catégories suivantes :\n",
    "-Portable\n",
    "-Sony_Playstation\n",
    "-Nintendo\n",
    "-Microsoft_Xbox\n",
    "-PC\n",
    "-Other\n",
    "\n",
    "Les catégories sont composés des plateformes suivantes : \n",
    "\n",
    "-Portable : [PSP, PSV, DS, GBA, 3DS, GB, GC ]\n",
    "-Sony_Playstation : [PS3, PS, PS2, PS4]\n",
    "-Nintendo : [Wii, WiiU]\n",
    "-Microsoft_Xbox: [X360, XB, XOne  ]\n",
    "-PC : [PC]\n",
    "-Other : [NES, SNES, N64, 2600, DC, SAT, GG, WS, TG16, 3DO ]\n",
    "\n",
    "\n",
    "Lors de notre première itération de ce modèle, nous voulions utiliser directement la platforme du jeu comme variable explicative. Or, cela introduisait de la multicolinéarité, c'est-à-dire que la matrice (X'X) qui était notre matrice de variable explicative ne pouvait pas être inversée.\n",
    "\n",
    "Alors, nous avions essayé de séparer toutes les plateformes en sous-catégories. Nous espérions que ceci pourrait éliminer la multi-colinéarité. Cette méthode n'a cepedant pas été fructueuse, car nous n'avions pas assez de données pour chaque plateforme. Donc, la régression de quelques palteformes comportait souvent un nombre de données inférieures à 100. Nous avons jugé ce nombre trop peu pour pouvoir bien prédire pour tous les jeux de cette plateforme. À vrai dire, peu de données utilisées lors de l'entrainement menait notre modèle à faire de l'\"Overfitting\", c'est-à-dire que le R² (coeff. de détermination de notre régression) de chaque modèle était bon pour notre jeu de données, mais pas bon pour prédire sur un nouveau jeu de données. En d'autre mots, notre analyse statistique correspondait trop étroitement à notre ensemble de données, mais ne prévoyais pas de manière fiable les observations futures.\n",
    "\n",
    "Il en découle ainsi que le  regroupement des plateformes en 6 sous-groupes nous semblait un bon compromis entre la création de différents sous-groupes tout en gardant le nombre de données assez élevé pour entraîner notre modèle et que le modèle soit valide.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: train not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: train not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[24]:1"
     ]
    }
   ],
   "source": [
    "plateform = collect(train[:Platform])\n",
    "platefromGeneral = plateform\n",
    "\n",
    "for i in eachindex(plateform)\n",
    "    if plateform[i] == \"PS3\"\n",
    "        platefromGeneral[i] = \"Sony_Playstation\" \n",
    "        \n",
    "    elseif plateform[i] == \"PS\"\n",
    "        platefromGeneral[i] = \"Sony_Playstation\" \n",
    "        \n",
    "    elseif plateform[i] == \"PS2\"\n",
    "        platefromGeneral[i] = \"Sony_Playstation\"\n",
    "        \n",
    "    elseif plateform[i] == \"PS4\"\n",
    "        platefromGeneral[i] = \"Sony_Playstation\"\n",
    "        \n",
    "    elseif plateform[i] == \"PSP\"\n",
    "        platefromGeneral[i] = \"Portable\"\n",
    "        \n",
    "    elseif plateform[i] == \"PSV\"\n",
    "        platefromGeneral[i] = \"Portable\"\n",
    "        \n",
    "    elseif plateform[i] == \"Wii\"\n",
    "        platefromGeneral[i] = \"Nintendo\"\n",
    "        \n",
    "    elseif plateform[i] == \"DS\"\n",
    "        platefromGeneral[i] = \"Portable\"\n",
    "        \n",
    "    elseif plateform[i] == \"GBA\"\n",
    "        platefromGeneral[i] = \"Portable\"\n",
    "        \n",
    "    elseif plateform[i] == \"3DS\"\n",
    "        platefromGeneral[i] = \"Portable\"\n",
    "        \n",
    "    elseif plateform[i] == \"WiiU\"\n",
    "        platefromGeneral[i] = \"Nintendo\"\n",
    "        \n",
    "    elseif plateform[i] == \"GB\"\n",
    "        platefromGeneral[i] = \"Portable\"\n",
    "        \n",
    "    elseif plateform[i] == \"GC\"\n",
    "        platefromGeneral[i] = \"Portable\"\n",
    "        \n",
    "    elseif plateform[i] == \"X360\"\n",
    "        platefromGeneral[i] = \"Microsoft_Xbox\"\n",
    "        \n",
    "    elseif plateform[i] == \"XB\"\n",
    "        platefromGeneral[i] = \"Microsoft_Xbox\"\n",
    "        \n",
    "    elseif plateform[i] == \"XOne\"\n",
    "        platefromGeneral[i] = \"Microsoft_Xbox\"\n",
    "        \n",
    "    elseif plateform[i] == \"PC\"\n",
    "        platefromGeneral[i] = \"PC\"\n",
    "        \n",
    "    else\n",
    "        platefromGeneral[i] = \"Other\"\n",
    "    end\n",
    "end\n",
    "train[:Platform_General] = platefromGeneral\n",
    "first(train,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme mentioné auparavant, la création des 2 nouvelles variables d'ingénieries nous aide à gérer les données manquantes dans notre collection de données. Effectivement, le plus grand problème de données manquantes est évité en utilisant la variable d'ingénierie Has_Count. C'est alors qu'il nous manquait le traitement des données venant de Other_Sales, JP_Sales et Year_Of_Release. Ces 3 variables sont les 3 variables explicatives utilisées pour prédire NA_SAles et Global_Sales.\n",
    "\n",
    "De plus, nous avons traité les données manquantes de Other_Sales, JP_Sales et Year_Of_Release. \n",
    "\n",
    "D'abord, notre stratégie était de calculer la moyenne de tous les jeux qui avaient une donnée pour ces caractéristiques et, ensuite, attribuer cette moyenne aux valeures manquantes de chaque variable. Or, Other_Sales et JP_Sales n'ont pas de donnée manquante. Ainsi, ces deux variables était correctes. \n",
    "\n",
    "Par contre, on ne pouvait appliquer notre statégie initiale sur la variable Year_Of_Release. Effectivement, on ne pouvait pas faire la moyenne de tous les jeux et remplacer les données manquantes par cette valeur puisque cela ne serait pas une date valide. Alors, nous avons opter pour une deuxième stratégie. Nous avons décidé de faire les moyennes pour remplacer les données manquantes, mais cette fois-ci en divisant par platforme. En d'autre mots, chaque plateforme avait une année moyenne pour ses jeux et les années manquantes était remplie par cette valeure. Nous avons rapidement réaliser que ceci était une bien meilleure façon de traiter les données, car les plateforme venant de différentes époque, les jeux sur ces platformes venait approximativement de cette époque. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: train not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: train not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[25]:1"
     ]
    }
   ],
   "source": [
    "first(train,5)\n",
    "plateformArray = [\"2600\",\"3DS\",\"DC\",\"DS\",\"GB\",\"GBA\",\"GC\",\"GEN\",\"N64\",\"NES\",\"NG\",\"PC\",\"PS\",\"PS2\",\"PS3\",\"PS4\",\"PSP\",\n",
    "    \"PSV\",\"SAT\",\"SCD\",\"SNES\",\"Wii\",\"WiiU\",\"WS\",\"X360\",\"XB\",\"XOne\"]\n",
    "\n",
    "totalTrainAllPlateform = deepcopy(train)\n",
    "deleterows!(totalTrainAllPlateform, 1:nrow(totalTrainAllPlateform))\n",
    "\n",
    "for i in eachindex(plateformArray)\n",
    "    trainSelectedPlatform =filter( row->(row[:Platform] == plateformArray[i]), train ) ## SELECT ONLY COLUNMS THAT PLATFORM IS PS2\n",
    "    trainSelectedPlatformLength = size(trainSelectedPlatform,2)\n",
    "    \n",
    "    if nrow(trainSelectedPlatform) == 0\n",
    "        print(\"\\n\")\n",
    "        print(\"Pas de donné pour $(plateformArray[i]) qui sont complète\")\n",
    "        print(\"\\n\")\n",
    "        print(\"\\n\")\n",
    "    else\n",
    "        ##Chargement données\n",
    "        japanSales = collect(trainSelectedPlatform[:JP_Sales])\n",
    "        otherSales = collect(trainSelectedPlatform[:Other_Sales])\n",
    "        userCount = collect(trainSelectedPlatform[:User_Count])\n",
    "        NASales = collect(trainSelectedPlatform[:NA_Sales])\n",
    "        globalSales = collect(trainSelectedPlatform[:Global_Sales])\n",
    "        yearOfRelease = collect(trainSelectedPlatform[:Year_of_Release])\n",
    "        criticCount = collect(trainSelectedPlatform[:Critic_Count])\n",
    "        ##Traitement de donné\n",
    "        ##Traitement JAPAN SELLS\n",
    "        meanJapanSales = mean(collect(skipmissing(trainSelectedPlatform[:JP_Sales])))\n",
    "        if meanJapanSales > -1\n",
    "            for a in eachindex(japanSales)\n",
    "                if (typeof(japanSales[a]) == Missing)\n",
    "                    japanSales[a] = meanJapanSales\n",
    "                    print(\"Missing JAPAN Sales\")\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            trainSelectedPlatform[:JP_Sales] = japanSales\n",
    "        end\n",
    "\n",
    "        ##Traitement year of release\n",
    "        meanYearOfRelease = Int(round((mean(collect(skipmissing(trainSelectedPlatform[:Year_of_Release]))))))\n",
    "        if meanYearOfRelease > -1\n",
    "            for b in eachindex(yearOfRelease)\n",
    "                if (typeof(yearOfRelease[b]) == Missing)\n",
    "                    yearOfRelease[b] = meanYearOfRelease           \n",
    "                end\n",
    "            end\n",
    "            trainSelectedPlatform[:Year_of_Release] = yearOfRelease\n",
    "        end\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "        ##Traitement Other SELLS\n",
    "        meanOtherSales = mean(collect(skipmissing(trainSelectedPlatform[:Other_Sales])))\n",
    "        if meanOtherSales > -1\n",
    "            for c in eachindex(otherSales)\n",
    "                if (typeof(otherSales[c]) == Missing)\n",
    "                    otherSales[c] = meanOtherSales\n",
    "                end\n",
    "            end\n",
    "            trainSelectedPlatform[:Other_Sales] = otherSales\n",
    "        end\n",
    "                \n",
    "        totalTrainAllPlateform = append!(totalTrainAllPlateform,trainSelectedPlatform)\n",
    "        \n",
    "    end\n",
    "   \n",
    "    \n",
    "    \n",
    "end\n",
    "rowIntotalTrainAllPlateformBefore = nrow(totalTrainAllPlateform)\n",
    "print(\"Le nombre de ligne dans totalTrainAllPlateform est de $(nrow(totalTrainAllPlateform))\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitements des donnés abérantes pour les Global_Sales  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nous enlevons tout les jeux dans les données qui se sont vendu à plus de 20 millions d'examplaire. Ces jeux sont des données abérantes, car elle ne représente pas la réalité de la plupart des jeux, donc ces données fausserais les données qui seront utilisées pour prédire l'échnatillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: totalTrainAllPlateform not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: totalTrainAllPlateform not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[26]:1"
     ]
    }
   ],
   "source": [
    "totalTrainAllPlateform =filter( row->(row[:Global_Sales] < 20), totalTrainAllPlateform )\n",
    "print(\"\\n\")\n",
    "print(\"Le nombre de ligne dans totalTrainAllPlateform est de $(nrow(totalTrainAllPlateform)) c'est-à-dire que nous avons trouvé $(rowIntotalTrainAllPlateformBefore - (nrow(totalTrainAllPlateform)) ) données abérantes donc,  ces jeux avaient plus de 20 millions de vente dans Global_Sales\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trouver Meilleur Modèle pour toute les plateformes et les Ventes Globals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commme mentionné au paravant, nous avons divisé nos données en groupes de platformes avec des sous-groupes de Has_Count et avons choisi le meilleur modèle pour chaque groupe. Cette première itération de recherche est pour déterminer la variable de prédiction de vente globale. \n",
    "\n",
    "Ici nous pouvons voir que plusieurs modèles sont créés avec 3 variables explicatives. Nous pouvons créer 7 modèles différents. Alors, pour chacun des 12 sous-groupe, la cellule suivante choisira qu'elle est le meilleur modèle à utiliser. \n",
    "\n",
    "Le R² et le R̃² sont calculés pour tous les modèles pour les 12 sous-catégories. C'est avec ces 2 mesures que nous choisissons lequel des 7 modèles sera choisi. Nous avons choisi arbitrairement de regarder si le R̃² est plus petit que le R². Nous considéront seulement l'écart à partir d'une différence de 0.03. En d'autres mots, avec un ecart plus petit que 0.03, nous allions choisir le modèle qui correspond au R̃² pour faire nos prédictions. Cependant si l'écart est plus grand que 0.03, nous allions garder le modèle avec le R²  le plus grand, car nous avons jugé que nous allions perdre trop de précision dans notre modèle. Cette perte de précision est du à l'avantage d'avoir moins de valeur explicative dans le modèle pour une régression moins correlé. En d'autres mots, moins de variables explicatives peut mener a une meilleure régression, mais pas un meilleur modèle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: totalTrainAllPlateform not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: totalTrainAllPlateform not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[27]:22"
     ]
    }
   ],
   "source": [
    "arrayModeleGlobalSales = []\n",
    "\n",
    "#Initialisation des modèles de régression\n",
    "M₁ = 1\n",
    "M₂ = 1\n",
    "M₃ = 1\n",
    "M₄ = 1\n",
    "M₅ = 1\n",
    "M₆ = 1\n",
    "M₇ = 1\n",
    "\n",
    "\n",
    "#Tableau avec le noms des groupes de plateformes\n",
    "platformGeneralArray = [\"Sony_Playstation\",\"Portable\",\"Nintendo\",\"Other\",\"Microsoft_Xbox\",\"PC\"]\n",
    "\n",
    "#Tableau qui indique si le sous-groupe a un Critic_Count et un User_Count. \n",
    "# 1: pour le sous-gorupe qui possède la caractéristique Has_Score\n",
    "# 0: pour le sous-groupe qui possède la caractéristique \n",
    "hasScoreArray = [1,0]\n",
    "   \n",
    "for i in eachindex(platformGeneralArray)\n",
    "    trainSelectedPlatformGeneric =filter( row->(row[:Platform_General] == platformGeneralArray[i]), totalTrainAllPlateform ) ## SELECT ONLY COLUNMS THAT PLATFORM IS PS2\n",
    "    for j in eachindex(hasScoreArray)\n",
    "        trainSelectedPlatform =filter( row->(row[:Has_Count] == hasScoreArray[j]), trainSelectedPlatformGeneric )\n",
    "        \n",
    "            #Supprimer les colonnes qui ne seront pas utilisé pour les modèles\n",
    "            deletecols!(trainSelectedPlatform, :Critic_Count)\n",
    "            deletecols!(trainSelectedPlatform, :Critic_Score)\n",
    "            deletecols!(trainSelectedPlatform, :User_Score)\n",
    "            deletecols!(trainSelectedPlatform, :User_Count)\n",
    "            deletecols!(trainSelectedPlatform, :Rating)\n",
    "            deletecols!(trainSelectedPlatform, :Developer)\n",
    "            deletecols!(trainSelectedPlatform, :Genre)\n",
    "            deletecols!(trainSelectedPlatform, :Publisher)\n",
    "            deletecols!(trainSelectedPlatform, :Platform)\n",
    "            \n",
    "    \n",
    "        if (nrow(trainSelectedPlatform))==0\n",
    "            print(\"Il n'y a pas de donnée pour les jeux de $(platformGeneralArray[i]) qui on un Has_Count = $(hasScoreArray[j]) \")\n",
    "        else\n",
    "            \n",
    "            print(\"\\n\")\n",
    "            print(\"nombre de row AVANT le dropMissing $(nrow(trainSelectedPlatform))\")\n",
    "          dropmissing!(trainSelectedPlatform)\n",
    "            print(\"\\n\")\n",
    "            print(\"nombre de row APRES le dropMissing $(nrow(trainSelectedPlatform))\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "            M₁ = lm(@formula(Global_Sales ~ JP_Sales), trainSelectedPlatform)\n",
    "            M₂ = lm(@formula(Global_Sales ~ Other_Sales), trainSelectedPlatform) \n",
    "            M₃ = lm(@formula(Global_Sales ~ Year_of_Release), trainSelectedPlatform) \n",
    "\n",
    "            M₄ = lm(@formula(Global_Sales ~ JP_Sales + Other_Sales), trainSelectedPlatform) \n",
    "            M₅ = lm(@formula(Global_Sales ~ JP_Sales + Year_of_Release), trainSelectedPlatform)\n",
    "            M₆ = lm(@formula(Global_Sales ~ Other_Sales + Year_of_Release), trainSelectedPlatform)\n",
    "\n",
    "            M₇ = lm(@formula(Global_Sales ~ JP_Sales + Other_Sales + Year_of_Release), trainSelectedPlatform)\n",
    "\n",
    "            ArrayModele = [M₁,M₂,M₃,M₄,M₅,M₆,M₇]\n",
    "\n",
    "\n",
    "            R² = zeros(length(ArrayModele))\n",
    "\n",
    "            for w in eachindex(ArrayModele)\n",
    "                e = residuals(ArrayModele[w])\n",
    "                globalSaleTrainSelectedPlatform = collect(trainSelectedPlatform[:Global_Sales])\n",
    "                SST = sum( (globalSaleTrainSelectedPlatform-mean(globalSaleTrainSelectedPlatform)).^2)\n",
    "                R²[w] =  1 - sum(e.^2)/SST\n",
    "            end\n",
    "            maxR² = findmax(R²)\n",
    "            println(\"Le meilleur modèle est le modèle $(maxR²[2]) avec un R² de $(maxR²[1]) pour les jeux de $(platformGeneralArray[i]) qui on un Has_Count = $(hasScoreArray[j])\")\n",
    "                \n",
    "            trainSelectedPlatformLength = length(trainSelectedPlatform)\n",
    "            n = trainSelectedPlatformLength\n",
    "\n",
    "            R̃² = zeros(length(ArrayModele));\n",
    "\n",
    "\n",
    "            for k in eachindex(ArrayModele)\n",
    "                p = length(coef(ArrayModele[k]))-1\n",
    "                e = residuals(ArrayModele[k])\n",
    "                SSE = sum(e.^2)\n",
    "                globalSaleTrainSelectedPlatform = collect(trainSelectedPlatform[:Global_Sales])\n",
    "                SST = sum( (globalSaleTrainSelectedPlatform-mean(globalSaleTrainSelectedPlatform)).^2)\n",
    "                R̃²[k] =  1 - SSE/SST * (n-1)/(n-p)\n",
    "            end\n",
    "\n",
    "            maxR̃² = findmax(R̃²)\n",
    "            \n",
    "            if maxR̃²[1] + 0.03 > maxR²[1]\n",
    "                push!(arrayModeleGlobalSales, ArrayModele[maxR̃²[2]])\n",
    "            else\n",
    "                push!(arrayModeleGlobalSales, ArrayModele[maxR²[2]])\n",
    "            end\n",
    "            println(\"Le meilleur modèle est le modèle $(maxR̃²[2]) avec un R̃² de $(maxR̃²[1]) pour les jeux de $(platformGeneralArray[i]) qui on un Has_Count = $(hasScoreArray[j])\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "        end    \n",
    "           \n",
    "    end\n",
    " end\n",
    "\n",
    "print(\"\\n\")\n",
    "print(length(arrayModeleGlobalSales))\n",
    "print(arrayModeleGlobalSales)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trouver le meilleur modèle pour toutes les plateformes pour les ventes en Amérique du Nord\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commme mentionné au paravant, nous avons divisé nos données en groupes de platformes et avons choisi le meilleur modèle pour chaque groupe. Cette première itération de recherche est pour déterminer la vairable de prédiction de vente en Amérique du Nord. \n",
    "\n",
    "La stratégie pour Global_Sales est réutilisé ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: totalTrainAllPlateform not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: totalTrainAllPlateform not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[28]:21"
     ]
    }
   ],
   "source": [
    "#Tableau dans lequel on garde en mémoire le meilleur modèle et ces caractéristique pour la prédiction futur\n",
    "arrayModeleNASales = []\n",
    "\n",
    "#Initialisation des modèles de régression\n",
    "M₁ = 1\n",
    "M₂ = 1\n",
    "M₃ = 1\n",
    "M₄ = 1\n",
    "M₅ = 1\n",
    "M₆ = 1\n",
    "M₇ = 1\n",
    "\n",
    "#Tableau avec le noms des groupes de plateformes\n",
    "platformGeneralArray = [\"Sony_Playstation\",\"Portable\",\"Nintendo\",\"Other\",\"Microsoft_Xbox\",\"PC\"]\n",
    "\n",
    "#Tableau qui indique si le sous-groupe a un Critic_Count et un User_Count. \n",
    "# 1: pour le sous-gorupe qui possède la caractéristique Has_Score\n",
    "# 0: pour le sous-groupe qui possède la caractéristique \n",
    "hasScoreArray = [1,0]\n",
    "for i in eachindex(platformGeneralArray)\n",
    "    trainSelectedPlatformGeneric =filter( row->(row[:Platform_General] == platformGeneralArray[i]), totalTrainAllPlateform ) ## SELECT ONLY COLUNMS THAT PLATFORM IS PS2\n",
    "    for j in eachindex(hasScoreArray)\n",
    "        trainSelectedPlatform =filter( row->(row[:Has_Count] == hasScoreArray[j]), trainSelectedPlatformGeneric )\n",
    "\n",
    "            deletecols!(trainSelectedPlatform, :Critic_Count)\n",
    "            deletecols!(trainSelectedPlatform, :Critic_Score)\n",
    "            deletecols!(trainSelectedPlatform, :User_Score)\n",
    "            deletecols!(trainSelectedPlatform, :User_Count)\n",
    "           deletecols!(trainSelectedPlatform, :Rating)\n",
    "            deletecols!(trainSelectedPlatform, :Developer)\n",
    "            deletecols!(trainSelectedPlatform, :Genre)\n",
    "            deletecols!(trainSelectedPlatform, :Publisher)\n",
    "            deletecols!(trainSelectedPlatform, :Platform)\n",
    "            \n",
    "    \n",
    "        if (nrow(trainSelectedPlatform))==0\n",
    "            print(\"Il n'y a pas de donnée pour les jeux de $(platformGeneralArray[i]) qui on un Has_Count = $(hasScoreArray[j]) \")\n",
    "        else\n",
    "            \n",
    "            print(\"\\n\")\n",
    "            print(\"nombre de lignes avant le dropMissing $(nrow(trainSelectedPlatform))\")\n",
    "            dropmissing!(trainSelectedPlatform)\n",
    "            print(\"\\n\")\n",
    "            print(\"nombre de lignes apres le dropMissing $(nrow(trainSelectedPlatform))\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "            M₁ = lm(@formula(NA_Sales ~ JP_Sales), trainSelectedPlatform)\n",
    "            M₂ = lm(@formula(NA_Sales ~ Other_Sales), trainSelectedPlatform) \n",
    "            M₃ = lm(@formula(NA_Sales ~ Year_of_Release), trainSelectedPlatform) \n",
    "            M₄ = lm(@formula(NA_Sales ~ JP_Sales + Other_Sales), trainSelectedPlatform) \n",
    "            M₅ = lm(@formula(NA_Sales ~ JP_Sales + Year_of_Release), trainSelectedPlatform)\n",
    "            M₆ = lm(@formula(NA_Sales ~ Other_Sales + Year_of_Release), trainSelectedPlatform)\n",
    "\n",
    "            M₇ = lm(@formula(NA_Sales ~ JP_Sales + Other_Sales + Year_of_Release), trainSelectedPlatform)\n",
    "\n",
    "            ArrayModele = [M₁,M₂,M₃,M₄,M₅,M₆,M₇]\n",
    "            \n",
    "            \n",
    "            R² = zeros(length(ArrayModele))\n",
    "\n",
    "            for w in eachindex(ArrayModele)\n",
    "                e = residuals(ArrayModele[w])\n",
    "                globalSaleTrainSelectedPlatform = collect(trainSelectedPlatform[:NA_Sales])\n",
    "                SST = sum( (globalSaleTrainSelectedPlatform-mean(globalSaleTrainSelectedPlatform)).^2)\n",
    "                R²[w] =  1 - sum(e.^2)/SST\n",
    "            end\n",
    "            maxR² = findmax(R²)\n",
    "            println(\"Le meilleur modèle est le modèle $(maxR²[2]) avec un R² de $(maxR²[1]) pour la plateform $(platformGeneralArray[i])\")\n",
    "              \n",
    "            trainSelectedPlatformLength = length(trainSelectedPlatform)\n",
    "            n = trainSelectedPlatformLength\n",
    "\n",
    "            R̃² = zeros(length(ArrayModele));\n",
    "\n",
    "             \n",
    "            for k in eachindex(ArrayModele)\n",
    "                p = length(coef(ArrayModele[k]))-1\n",
    "                e = residuals(ArrayModele[k])\n",
    "                SSE = sum(e.^2)\n",
    "                globalSaleTrainSelectedPlatform = collect(trainSelectedPlatform[:NA_Sales])\n",
    "                SST = sum( (globalSaleTrainSelectedPlatform-mean(globalSaleTrainSelectedPlatform)).^2)\n",
    "                R̃²[k] =  1 - SSE/SST * (n-1)/(n-p) \n",
    "            end\n",
    "\n",
    "            maxR̃² = findmax(R̃²)\n",
    "            if maxR̃²[1] + 0.03 > maxR²[1]\n",
    "                push!(arrayModeleNASales,ArrayModele[maxR̃²[2]])               \n",
    "            else\n",
    "                push!(arrayModeleNASales,ArrayModele[maxR²[2]])\n",
    "            end\n",
    "            println(\"Le meilleur modèle est le modèle $(maxR̃²[2]) avec un R̃² de $(maxR̃²[1]) pour la plateforme $(platformGeneralArray[i])\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "        end    \n",
    "           \n",
    "    end\n",
    " end\n",
    "\n",
    "print(\"\\n\")\n",
    "print(length(arrayModeleNASales))\n",
    "print(arrayModeleNASales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement de donné avec les données de Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette section, nous formattons nos données de tests pour être compatible avec notre modèle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: \"test3.csv\" is not a valid file",
     "output_type": "error",
     "traceback": [
      "ArgumentError: \"test3.csv\" is not a valid file",
      "",
      "Stacktrace:",
      " [1] #File#1(::Int64, ::Bool, ::Int64, ::Nothing, ::Int64, ::Nothing, ::Bool, ::Nothing, ::Bool, ::Array{String,1}, ::String, ::String, ::Bool, ::Char, ::Nothing, ::Nothing, ::Char, ::Nothing, ::Nothing, ::Nothing, ::Nothing, ::Nothing, ::Dict{Type,Type}, ::Symbol, ::Bool, ::Bool, ::Bool, ::Bool, ::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::Type, ::String) at C:\\Users\\mbela\\.julia\\packages\\CSV\\eWuJV\\src\\CSV.jl:135",
      " [2] Type at C:\\Users\\mbela\\.julia\\packages\\CSV\\eWuJV\\src\\CSV.jl:135 [inlined]",
      " [3] #read#105(::Bool, ::Dict{Int64,Function}, ::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::Function, ::String, ::Type) at C:\\Users\\mbela\\.julia\\packages\\CSV\\eWuJV\\src\\CSV.jl:310",
      " [4] read at C:\\Users\\mbela\\.julia\\packages\\CSV\\eWuJV\\src\\CSV.jl:300 [inlined] (repeats 2 times)",
      " [5] top-level scope at In[29]:1"
     ]
    }
   ],
   "source": [
    "test = CSV.read(\"test.csv\")\n",
    "plateform = collect(test[:Platform])\n",
    "platefromGen = plateform\n",
    "\n",
    "\n",
    "for i in eachindex(plateform)\n",
    "    if plateform[i] == \"PS3\"\n",
    "        platefromGen[i] = \"Sony_Playstation\" \n",
    "        \n",
    "    elseif plateform[i] == \"PS\"\n",
    "        platefromGen[i] = \"Sony_Playstation\" \n",
    "        \n",
    "    elseif plateform[i] == \"PS2\"\n",
    "        platefromGen[i] = \"Sony_Playstation\"\n",
    "        \n",
    "    elseif plateform[i] == \"PS4\"\n",
    "        platefromGen[i] = \"Sony_Playstation\"\n",
    "        \n",
    "    elseif plateform[i] == \"PSP\"\n",
    "        platefromGen[i] = \"Portable\"\n",
    "        \n",
    "    elseif plateform[i] == \"PSV\"\n",
    "        platefromGen[i] = \"Portable\"\n",
    "        \n",
    "    elseif plateform[i] == \"Wii\"\n",
    "        platefromGen[i] = \"Nintendo\"\n",
    "        \n",
    "    elseif plateform[i] == \"DS\"\n",
    "        platefromGen[i] = \"Portable\"\n",
    "        \n",
    "    elseif plateform[i] == \"GBA\"\n",
    "        platefromGen[i] = \"Portable\"\n",
    "        \n",
    "    elseif plateform[i] == \"3DS\"\n",
    "        platefromGen[i] = \"Portable\"\n",
    "        \n",
    "    elseif plateform[i] == \"WiiU\"\n",
    "        platefromGen[i] = \"Nintendo\"\n",
    "\n",
    "    elseif plateform[i] == \"GB\"\n",
    "        platefromGen[i] = \"Portable\"\n",
    "        \n",
    "    elseif plateform[i] == \"GC\"\n",
    "        platefromGen[i] = \"Portable\"\n",
    "        \n",
    "    elseif plateform[i] == \"X360\"\n",
    "        platefromGen[i] = \"Microsoft_Xbox\"\n",
    "        \n",
    "    elseif plateform[i] == \"XB\"\n",
    "        platefromGen[i] = \"Microsoft_Xbox\"\n",
    "        \n",
    "    elseif plateform[i] == \"XOne\"\n",
    "        platefromGen[i] = \"Microsoft_Xbox\"\n",
    "        \n",
    "    elseif plateform[i] == \"PC\"\n",
    "        platefromGen[i] = \"PC\"\n",
    "        \n",
    "    else\n",
    "        platefromGen[i] = \"Other\"\n",
    "    end\n",
    "end\n",
    "test[:Platform_General] = platefromGen\n",
    "first(test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: test not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: test not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[30]:1"
     ]
    }
   ],
   "source": [
    "userCount = collect(test[:User_Count])\n",
    "criticCount = collect(test[:Critic_Count])\n",
    "hasCount = userCount\n",
    "\n",
    "for i in eachindex(userCount)\n",
    "    if typeof(userCount[i]) == Missing || typeof(criticCount[i]) == Missing\n",
    "        hasCount[i] = 0\n",
    "        \n",
    "    else\n",
    "        hasCount[i] = 1 \n",
    "        \n",
    "    end\n",
    "end\n",
    "test[:Has_Count] = hasCount\n",
    "first(test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: test not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: test not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[31]:1"
     ]
    }
   ],
   "source": [
    "first(test,5)\n",
    "plateformArray = [\"2600\",\"3DS\",\"DC\",\"DS\",\"GB\",\"GBA\",\"GC\",\"GEN\",\"N64\",\"NES\",\"NG\",\"PC\",\"PS\",\"PS2\",\"PS3\",\"PS4\",\"PSP\",\n",
    "    \"PSV\",\"SAT\",\"SCD\",\"SNES\",\"Wii\",\"WiiU\",\"WS\",\"X360\",\"XB\",\"XOne\", \"GG\", \"3DO\"]\n",
    "\n",
    "totalTestAllPlateform = deepcopy(test)\n",
    "deleterows!(totalTestAllPlateform, 1:nrow(totalTestAllPlateform))\n",
    "\n",
    "for i in eachindex(plateformArray)\n",
    "    testSelectedPlatform =filter( row->(row[:Platform] == plateformArray[i]), test ) ## SELECT ONLY COLUNMS THAT PLATFORM IS PS2\n",
    "    testSelectedPlatformLength = size(testSelectedPlatform,2)\n",
    "    \n",
    "    if nrow(testSelectedPlatform) == 0\n",
    "        print(\"\\n\")\n",
    "        print(\"Pas de donné pour $(plateformArray[i]) qui sont complète\")\n",
    "        print(\"\\n\")\n",
    "        print(\"\\n\")\n",
    "    else\n",
    "        ##Chargement données\n",
    "        japanSales = collect(testSelectedPlatform[:JP_Sales])\n",
    "        otherSales = collect(testSelectedPlatform[:Other_Sales])\n",
    "        userCount = collect(testSelectedPlatform[:User_Count])\n",
    "        \n",
    "    \n",
    "        yearOfRelease = collect(testSelectedPlatform[:Year_of_Release])\n",
    "        criticCount = collect(testSelectedPlatform[:Critic_Count])\n",
    "        ##Traitement de donné\n",
    "        ##Traitement JAPAN SELLS\n",
    "        meanJapanSales = mean(collect(skipmissing(testSelectedPlatform[:JP_Sales])))\n",
    "        if meanJapanSales > -1\n",
    "            for a in eachindex(japanSales)\n",
    "                if (typeof(japanSales[a]) == Missing)\n",
    "                    japanSales[a] = meanJapanSales\n",
    "                    print(\"Missing JAPAN Sales\")\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            testSelectedPlatform[:JP_Sales] = japanSales\n",
    "        end\n",
    "\n",
    "        ##Traitement year of release\n",
    "        meanYearOfRelease = Int(round((mean(collect(skipmissing(testSelectedPlatform[:Year_of_Release]))))))\n",
    "        if meanYearOfRelease > -1\n",
    "            for b in eachindex(yearOfRelease)\n",
    "                if (typeof(yearOfRelease[b]) == Missing)\n",
    "                    yearOfRelease[b] = meanYearOfRelease           \n",
    "                end\n",
    "            end\n",
    "            testSelectedPlatform[:Year_of_Release] = yearOfRelease\n",
    "        end\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "        ##Traitement Other SELLS\n",
    "        meanOtherSales = mean(collect(skipmissing(testSelectedPlatform[:Other_Sales])))\n",
    "        if meanOtherSales > -1\n",
    "            for c in eachindex(otherSales)\n",
    "                if (typeof(otherSales[c]) == Missing)\n",
    "                    otherSales[c] = meanOtherSales\n",
    "                end\n",
    "            end\n",
    "            testSelectedPlatform[:Other_Sales] = otherSales\n",
    "        end\n",
    "                \n",
    "        totalTestAllPlateform = append!(totalTestAllPlateform,testSelectedPlatform)\n",
    "        \n",
    "    end\n",
    "   \n",
    "    \n",
    "    \n",
    "end\n",
    "\n",
    "print(\"Il y a $(nrow(totalTestAllPlateform)) lignes dans totalTestAllPlatform\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la prédiction des colonnes NA_Sales et Global_Sales, nous regroupons les données en sous-groupe qui sont exactement les même que dans la sélection de modèle. Cependant, dans cette section, pour chaque donnée qui fait parti d'un des 12 sous-groupes, nous évaluons les 2 colonnes manquantes avec le meilleur modèle pour ce sous-groupe. La fin de cette section regroupe et écrit les données dans un CSV dans le format accepté par Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: totalTestAllPlateform not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: totalTestAllPlateform not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[32]:7"
     ]
    }
   ],
   "source": [
    "#Création d'un DataFrame pour contenir les prédictions qui seront écrits dans le CSV final\n",
    "totalPredictions = DataFrame(ID = Int64[], NA_Sales = Float64[], Global_Sales = Float64[])\n",
    "\n",
    "\n",
    "#Parcourir le tableau de catégories de plateforme et le tableau de Has_Count pour trier les données selon leur catégorie\n",
    "for t in eachindex(platformGeneralArray)\n",
    "    testSelectedPlatformGeneric = filter( row->(row[:Platform_General] == platformGeneralArray[t]), totalTestAllPlateform)\n",
    "    for j in eachindex(hasScoreArray)\n",
    "        testSelectedPlatform =filter( row->(row[:Has_Count] == hasScoreArray[j]), testSelectedPlatformGeneric )\n",
    "    \n",
    "        testSelectedPlatformLength = size(testSelectedPlatform,2)\n",
    "        numberOfRows = size(testSelectedPlatform,1)\n",
    "\n",
    "        deletecols!(testSelectedPlatform, :Critic_Count)\n",
    "        deletecols!(testSelectedPlatform, :Critic_Score)\n",
    "        deletecols!(testSelectedPlatform, :User_Score)\n",
    "        deletecols!(testSelectedPlatform, :User_Count)\n",
    "        deletecols!(testSelectedPlatform, :Rating)\n",
    "        deletecols!(testSelectedPlatform, :Developer)\n",
    "        deletecols!(testSelectedPlatform, :Genre)\n",
    "        deletecols!(testSelectedPlatform, :Publisher)\n",
    "        deletecols!(testSelectedPlatform, :Platform)\n",
    "    \n",
    "        if platformGeneralArray[t]== \"Sony_Playstation\" && hasScoreArray[j] == 1\n",
    "            \n",
    "\n",
    "           \n",
    "        \n",
    "            NA_Sales = predict(arrayModeleNASales[1],testSelectedPlatform)\n",
    "            Global_Sales = predict(arrayModeleGlobalSales[1],testSelectedPlatform)\n",
    "            predictions = DataFrame(ID = testSelectedPlatform[:ID], NA_Sales = NA_Sales, Global_Sales = Global_Sales)\n",
    "            totalPredictions =append!(totalPredictions, predictions)\n",
    "            \n",
    "        elseif platformGeneralArray[t]== \"Sony_Playstation\" && hasScoreArray[j] == 0\n",
    "            \n",
    "            NA_Sales = predict(arrayModeleNASales[2],testSelectedPlatform)\n",
    "            Global_Sales = predict(arrayModeleGlobalSales[2],testSelectedPlatform)\n",
    "            predictions = DataFrame(ID = testSelectedPlatform[:ID], NA_Sales = NA_Sales, Global_Sales = Global_Sales)\n",
    "            totalPredictions =append!(totalPredictions, predictions)\n",
    "                \n",
    "        elseif platformGeneralArray[t]== \"Portable\" && hasScoreArray[j] == 1\n",
    "            \n",
    "           \n",
    "        \n",
    "            NA_Sales = predict(arrayModeleNASales[3],testSelectedPlatform)\n",
    "            Global_Sales = predict(arrayModeleGlobalSales[3],testSelectedPlatform)\n",
    "            predictions = DataFrame(ID = testSelectedPlatform[:ID], NA_Sales = NA_Sales, Global_Sales = Global_Sales)\n",
    "            totalPredictions =append!(totalPredictions, predictions)\n",
    "            \n",
    "            \n",
    "        elseif platformGeneralArray[t]== \"Portable\" && hasScoreArray[j] == 0 \n",
    "            \n",
    "        \n",
    "            NA_Sales = predict(arrayModeleNASales[4],testSelectedPlatform)\n",
    "            Global_Sales = predict(arrayModeleGlobalSales[4],testSelectedPlatform)\n",
    "            predictions = DataFrame(ID = testSelectedPlatform[:ID], NA_Sales = NA_Sales, Global_Sales = Global_Sales)\n",
    "            totalPredictions =append!(totalPredictions, predictions)\n",
    "            \n",
    "            \n",
    "        \n",
    "        elseif platformGeneralArray[t]== \"Nintendo\" && hasScoreArray[j] == 1\n",
    "        \n",
    "        \n",
    "            NA_Sales = predict(arrayModeleNASales[5],testSelectedPlatform)\n",
    "            Global_Sales = predict(arrayModeleGlobalSales[5],testSelectedPlatform) \n",
    "            predictions = DataFrame(ID = testSelectedPlatform[:ID], NA_Sales = NA_Sales, Global_Sales = Global_Sales)\n",
    "            totalPredictions =append!(totalPredictions, predictions)\n",
    "            \n",
    "            \n",
    "        elseif platformGeneralArray[t]== \"Nintendo\" && hasScoreArray[j] == 0\n",
    "           \n",
    "        \n",
    "            NA_Sales = predict(arrayModeleNASales[6],testSelectedPlatform)\n",
    "            Global_Sales = predict(arrayModeleGlobalSales[6],testSelectedPlatform) \n",
    "            predictions = DataFrame(ID = testSelectedPlatform[:ID], NA_Sales = NA_Sales, Global_Sales = Global_Sales)\n",
    "            totalPredictions =append!(totalPredictions, predictions)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        elseif platformGeneralArray[t]== \"Other\" && hasScoreArray[j] == 1\n",
    "            \n",
    "        \n",
    "            NA_Sales = predict(arrayModeleNASales[7],testSelectedPlatform)\n",
    "            Global_Sales = predict(arrayModeleGlobalSales[7],testSelectedPlatform)         \n",
    "            predictions = DataFrame(ID = testSelectedPlatform[:ID], NA_Sales = NA_Sales, Global_Sales = Global_Sales)\n",
    "            totalPredictions =append!(totalPredictions, predictions)\n",
    "            \n",
    "        elseif platformGeneralArray[t]== \"Other\" && hasScoreArray[j] == 0\n",
    "            \n",
    "        \n",
    "            NA_Sales = predict(arrayModeleNASales[8],testSelectedPlatform)\n",
    "            Global_Sales = predict(arrayModeleGlobalSales[8],testSelectedPlatform)         \n",
    "            predictions = DataFrame(ID = testSelectedPlatform[:ID], NA_Sales = NA_Sales, Global_Sales = Global_Sales)\n",
    "            totalPredictions =append!(totalPredictions, predictions)\n",
    "            \n",
    "            \n",
    "        elseif platformGeneralArray[t]== \"Microsoft_Xbox\"  && hasScoreArray[j] == 1\n",
    "            \n",
    "            NA_Sales = predict(arrayModeleNASales[9],testSelectedPlatform)\n",
    "            Global_Sales = predict(arrayModeleGlobalSales[9],testSelectedPlatform)     \n",
    "            predictions = DataFrame(ID = testSelectedPlatform[:ID], NA_Sales = NA_Sales, Global_Sales = Global_Sales)\n",
    "            totalPredictions =append!(totalPredictions, predictions)\n",
    "            \n",
    "            \n",
    "        elseif platformGeneralArray[t]== \"Microsoft_Xbox\"  && hasScoreArray[j] == 0\n",
    "            \n",
    "            NA_Sales = predict(arrayModeleNASales[10],testSelectedPlatform)\n",
    "            Global_Sales = predict(arrayModeleGlobalSales[10],testSelectedPlatform)     \n",
    "            predictions = DataFrame(ID = testSelectedPlatform[:ID], NA_Sales = NA_Sales, Global_Sales = Global_Sales)\n",
    "            totalPredictions =append!(totalPredictions, predictions)\n",
    "            \n",
    "            \n",
    "        elseif platformGeneralArray[t]== \"PC\"  && hasScoreArray[j] == 1\n",
    "        \n",
    "        \n",
    "            NA_Sales = predict(arrayModeleNASales[11],testSelectedPlatform)\n",
    "            Global_Sales = predict(arrayModeleGlobalSales[11],testSelectedPlatform)\n",
    "            predictions = DataFrame(ID = testSelectedPlatform[:ID], NA_Sales = NA_Sales, Global_Sales = Global_Sales)\n",
    "            totalPredictions =append!(totalPredictions, predictions)\n",
    "            \n",
    "            \n",
    "        elseif platformGeneralArray[t]== \"PC\"  && hasScoreArray[j] == 0\n",
    "\n",
    "        \n",
    "            NA_Sales = predict(arrayModeleNASales[12],testSelectedPlatform)\n",
    "            Global_Sales = predict(arrayModeleGlobalSales[12],testSelectedPlatform)\n",
    "            predictions = DataFrame(ID = testSelectedPlatform[:ID], NA_Sales = NA_Sales, Global_Sales = Global_Sales)\n",
    "            totalPredictions =append!(totalPredictions, predictions)\n",
    "            \n",
    "        end          \n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Écriture dans le CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Il y a 3 colonnes dans le DataFrame totalPredictions\n",
      "Il y a 0 lignes dans le DataFrame totalPredictions alors celui-ci est valide pour la remise sur Kaggle"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `length(df::AbstractDataFrame)` is deprecated, use `size(df, 2)` instead.\n",
      "│   caller = top-level scope at In[33]:3\n",
      "└ @ Core In[33]:3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Benchmark_predictions_Best_Team.csv\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"Il y a $(length(totalPredictions)) colonnes dans le DataFrame totalPredictions\")\n",
    "print(\"\\n\")\n",
    "print(\"Il y a $(nrow(totalPredictions)) lignes dans le DataFrame totalPredictions alors celui-ci est valide pour la remise sur Kaggle\")\n",
    "CSV.write(\"Benchmark_predictions_Best_Team.csv\",totalPredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant la soumission de notre modèle sur Kaggle, nous savions que les tentatives étaient limitées sur la plateforme. Il était alors utile d'utiliser la validation croisée pour estimer la force de notre modèle de prédiction. \n",
    "\n",
    "Dans notre case, la validation croisée se fait en 2 étapes :\n",
    "\n",
    "-Premièrement, nous avons aléatoirement mélangé la collection de données d'entrainement et nous l'avons divisé en 2 sections : entrainement et test.\n",
    "\n",
    "Alors, après cette étape, nous pouvons refaire le meme processus de sélection de modèle, mais avec les nouvelles collections de données. La collection de données de test qui est créé à partir des données d'entrainement nous a permi d'avoir l'information sur les 2 colonnes qui nous manqueraient normalement dans notre collection de données de test (sur Kaggle par exemple).\n",
    "\n",
    "-Deuxièmement, étant donné que nous avons créé une collection de données de test qui est complète, nous pouvons maintenant déterminer le RMSE pour les 2 colonnes que nous allons devoir prédire. \n",
    "\n",
    "Le RMSE est le \"Rooted Mean Squared Error\" qui sert de pointage pour évaluer les modèles lors de leur remise sur Kaggle.\n",
    "\n",
    "Alors lors de l'étape de prédiction vu plus haut, nous remplaceons la vrai collection de données de test par celle tirée des données d'entrainement et nous effectuons la prédiction pour les 2 colonnes manquantes (NA_Sales et Global_Sales). Ensuite, le RMSE nous servira de comparaison entre la valeur observée et la valeur prédite.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première cellule dans la section du traitement des données peut etre remplacer par celle-ci si nous voulons faire de la validation croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: \"train3.csv\" is not a valid file",
     "output_type": "error",
     "traceback": [
      "ArgumentError: \"train3.csv\" is not a valid file",
      "",
      "Stacktrace:",
      " [1] #File#1(::Int64, ::Bool, ::Int64, ::Nothing, ::Int64, ::Nothing, ::Bool, ::Nothing, ::Bool, ::Array{String,1}, ::String, ::String, ::Bool, ::Char, ::Nothing, ::Nothing, ::Char, ::Nothing, ::Nothing, ::Nothing, ::Nothing, ::Nothing, ::Dict{Type,Type}, ::Symbol, ::Bool, ::Bool, ::Bool, ::Bool, ::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::Type, ::String) at C:\\Users\\mbela\\.julia\\packages\\CSV\\eWuJV\\src\\CSV.jl:135",
      " [2] Type at C:\\Users\\mbela\\.julia\\packages\\CSV\\eWuJV\\src\\CSV.jl:135 [inlined]",
      " [3] #read#105(::Bool, ::Dict{Int64,Function}, ::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}, ::Function, ::String, ::Type) at C:\\Users\\mbela\\.julia\\packages\\CSV\\eWuJV\\src\\CSV.jl:310",
      " [4] read at C:\\Users\\mbela\\.julia\\packages\\CSV\\eWuJV\\src\\CSV.jl:300 [inlined] (repeats 2 times)",
      " [5] top-level scope at In[34]:1"
     ]
    }
   ],
   "source": [
    "train = CSV.read(\"train.csv\")\n",
    "\n",
    "shuffleobs(train)\n",
    "train, test = splitobs(train, at = 0.80);\n",
    "train = DataFrame(train)\n",
    "test = DataFrame(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule écriture dans le CSV peut etre remplacer par la celulle présentée ci-bas pour avoir le résultat de validation croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: test not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: test not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[35]:4"
     ]
    }
   ],
   "source": [
    "PREDICTION_ID = collect(totalPredictions[:ID])\n",
    "PREDICTION_NA_SALES = collect(totalPredictions[:NA_Sales])\n",
    "PREDICTION_GLOBAL_SALES = collect(totalPredictions[:Global_Sales])\n",
    "OBSERVED_ID = collect(test[:ID])\n",
    "OBSERVED_NA_SALES = collect(test[:NA_Sales])\n",
    "OBSERVED_GLOBAL_SALES = collect(test[:Global_Sales])\n",
    "print(\"\\n\")\n",
    "\n",
    "preditMOINSObserverALA2NA_SALES = []\n",
    "preditMOINSObserverALA2GLOBAL_SALES = []\n",
    "for r in eachindex(PREDICTION_ID)\n",
    "    for u in eachindex(OBSERVED_ID)\n",
    "        if PREDICTION_ID[r] == OBSERVED_ID[u]\n",
    "            push!(preditMOINSObserverALA2NA_SALES,(PREDICTION_NA_SALES[r] - OBSERVED_NA_SALES[u])^2)\n",
    "            \n",
    "            push!(preditMOINSObserverALA2GLOBAL_SALES,(PREDICTION_GLOBAL_SALES[r] - OBSERVED_GLOBAL_SALES[u])^2)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "print(length(preditMOINSObserverALA2NA_SALES))\n",
    "print(\"\\n\")\n",
    "print(length(preditMOINSObserverALA2GLOBAL_SALES))\n",
    "meanRootedNA_SALES = sqrt(mean(preditMOINSObserverALA2NA_SALES))\n",
    "meanRootedGlobal_SALES = sqrt(mean(preditMOINSObserverALA2GLOBAL_SALES))\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print(\"LE RMSE  pour NA_SALES = $(meanRootedNA_SALES)\")\n",
    "print(\"\\n\")\n",
    "print(\"LE RMSE  pour Global_SALES = $(meanRootedGlobal_SALES)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons eu les résultats suivants lors de notre validation croisée en séparant les données d'entrainements pour avoir 80% des données encore pour l'entrainement et 20% des données pour les données de test.\n",
    "\n",
    "\"LE RMSE  pour NA_SALES = 0.5315586884852461\"\n",
    "\n",
    "\"LE RMSE pour Global_SALES = 0.6386314060105366\"\n",
    "\n",
    "Ces résultats était assez prometeur, car nous n'avions pas encore eu de pointage ausi bas sur Kaggle. \n",
    "C'est pourquoi nous avons décidé de le soumettre sur Kaggle où nous avons eu un pointage de 0.47984. \n",
    "\n",
    "Cette différence entre le RMSE de la validation croisée et le pointage Kaggle peut etre justifiée par le fait que les données pour la validation croisée ne sont pas les même données que que nous devons prédire sur Kaggle. Alors, il est normal que le pointage ne soit pas le même.\n",
    "\n",
    "Une validation croisée fait avec la méthode du K-Fold qui consiste à séparer les données d'entrainements en plusieurs sous-groupes et faire toutes les combinaisons possibles (entrainenement et test) avec ces sous-groupes aurait rendu notre estimation du RMSE plus précise.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En conclusion, nous avons énormément appris lors de ce travail. En effet, nous considérons ce premier travail de machine learning un véritable succès. \n",
    "\n",
    "Or, ce succès est venu avec son lot de problématiques. La première erreur que nous avons faite, c'est d'avoir négligé l'exploration de données initales. En effet, lors de la génèse de notre travail, nous avons concentré nos efforts sur la création d'un modèle fonctionnel. Ainsi, nous avons tardé à bien comprendre notre jeu de données et, par conséquent, avons tardé à trouver de bonnes variables explicatives. Deuxièment, nous n'avons pas procédé de facon rigoureuse et structurée. Ceci à été très problématique lorsque notre projet à pris de l'empleur et que celui-ci s'est complexifié, car nous avions de la misère à y apporter des modifications de facon efficace. Ainsi, nous avions beaucoup de répétition de code. Une solution efficace aurait été de faire des fonctions que nous arrions pu utiliser et réutiliser tout au long du projet. \n",
    "\n",
    "Finalement, nous croyons que le modèle peut encore s'améliorer de deux façons majeures. En effet, notre hypothèse est que le modèle pourrait être améliorer en enlevant les données abérantes. Dans la partie d'exploration de données, nous ciblons des données qui sont clairement abérrantes. Les enlever du modèle d'entraiement pourrait diminuer notre erreure de prédiction. Deuxièmement, nous croyons que nous pouvons essayer plus de variables explicatives. En effet, nous modèle comprends seulement 3 variables explicatives et deux vairables de division de groupe (Platform et has_Count). Alors, nous croyons qu'ajouter des variables comme le 'genre' et le 'rating' d'un jeu à nos trois variables explicatives pourrait diminuer notre erreur de prédiction. Finalement, il serait avisé d'utiliser pour la régression les variables reliées aux \"scores\" des jeux. Une manière de procéder serait de créer une variable d'ingéniérie qui pondère l'importance d'un score en fonction du nombre d'évaluations. Puisque nous avons généré séparément nos modèles en fonction de la plateforme et du score, nous pourrions utiliser ce score pondéré seulement pour les modèles où les données sont suffisantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.7.0",
   "language": "julia",
   "name": "julia-0.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
